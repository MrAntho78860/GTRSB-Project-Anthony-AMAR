{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Reconnaissance de Panneaux Routiers avec CNN\n",
        "## German Traffic Sign Recognition Benchmark (GTSRB)\n",
        "\n",
        "---\n",
        "\n",
        "**Projet académique de compensation - CNRS FIDLE**\n",
        "\n",
        "Ce notebook présente l'implémentation complète d'un réseau de neurones convolutif (CNN) pour la classification de panneaux routiers allemands.\n",
        "\n",
        "### Table des matières\n",
        "1. [Introduction et Objectifs](#1-introduction)\n",
        "2. [Configuration de l'environnement](#2-configuration)\n",
        "3. [Exploration du dataset GTSRB](#3-exploration)\n",
        "4. [Prétraitement des données](#4-preprocessing)\n",
        "5. [Architecture du CNN](#5-architecture)\n",
        "6. [Entraînement du modèle](#6-training)\n",
        "7. [Évaluation des performances](#7-evaluation)\n",
        "8. [Analyse des erreurs](#8-errors)\n",
        "9. [Conclusion et perspectives](#9-conclusion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 1. Introduction et Objectifs <a id='1-introduction'></a>\n",
        "\n",
        "### 1.1 Contexte\n",
        "\n",
        "La reconnaissance automatique de panneaux routiers est un enjeu majeur pour les systèmes de conduite autonome et les aides à la conduite (ADAS). Le **German Traffic Sign Recognition Benchmark (GTSRB)** est un dataset de référence dans ce domaine, contenant plus de 50 000 images de panneaux routiers allemands répartis en **43 classes**.\n",
        "\n",
        "### 1.2 Objectifs du projet\n",
        "\n",
        "1. **Comprendre** le pipeline complet de classification d'images avec deep learning\n",
        "2. **Implémenter** un CNN performant adapté au problème\n",
        "3. **Évaluer** les performances de manière rigoureuse\n",
        "4. **Analyser** les forces et faiblesses du modèle\n",
        "\n",
        "### 1.3 Méthodologie\n",
        "\n",
        "Nous suivons l'approche pédagogique du CNRS-FIDLE:\n",
        "- Compréhension avant performance brute\n",
        "- Visualisation à chaque étape\n",
        "- Analyse critique des résultats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 2. Configuration de l'environnement <a id='2-configuration'></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports standards\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "\n",
        "# Deep Learning\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Métriques\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Configuration matplotlib\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "plt.rcParams['font.size'] = 11\n",
        "\n",
        "# Reproductibilité\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "# Ajouter le dossier src au path\n",
        "sys.path.insert(0, os.path.join(os.getcwd(), '..', 'src'))\n",
        "\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "print(f\"GPU disponible: {len(tf.config.list_physical_devices('GPU')) > 0}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Chemins du projet\n",
        "BASE_DIR = os.path.dirname(os.getcwd())  # Remonter d'un niveau depuis notebooks/\n",
        "DATA_PATH = os.path.join(BASE_DIR, 'GTSRB-Training_fixed', 'GTSRB', 'Training')\n",
        "MODELS_DIR = os.path.join(BASE_DIR, 'models')\n",
        "FIGURES_DIR = os.path.join(BASE_DIR, 'figures')\n",
        "\n",
        "# Créer les dossiers si nécessaire\n",
        "os.makedirs(MODELS_DIR, exist_ok=True)\n",
        "os.makedirs(FIGURES_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"Dossier donnees: {DATA_PATH}\")\n",
        "print(f\"   Existe: {os.path.exists(DATA_PATH)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 3. Exploration du dataset GTSRB <a id='3-exploration'></a>\n",
        "\n",
        "Le dataset GTSRB contient:\n",
        "- **43 classes** de panneaux routiers\n",
        "- **~39,209 images** d'entraînement\n",
        "- **~12,630 images** de test\n",
        "- Images de **tailles variables** (15×15 à 250×250 pixels)\n",
        "\n",
        "### 3.1 Structure du dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compter les images par classe\n",
        "class_counts = []\n",
        "\n",
        "for class_id in range(43):\n",
        "    class_folder = os.path.join(DATA_PATH, format(class_id, '05d'))\n",
        "    if os.path.exists(class_folder):\n",
        "        # Compter les fichiers .ppm\n",
        "        count = len([f for f in os.listdir(class_folder) if f.endswith('.ppm')])\n",
        "        class_counts.append(count)\n",
        "    else:\n",
        "        class_counts.append(0)\n",
        "\n",
        "print(\"Statistiques du dataset:\")\n",
        "print(\"   Nombre de classes: 43\")\n",
        "print(f\"   Total d'images: {sum(class_counts)}\")\n",
        "print(f\"   Min par classe: {min(class_counts)}\")\n",
        "print(f\"   Max par classe: {max(class_counts)}\")\n",
        "print(f\"   Moyenne: {np.mean(class_counts):.1f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualiser la distribution des classes\n",
        "fig, ax = plt.subplots(figsize=(14, 6))\n",
        "\n",
        "bars = ax.bar(range(43), class_counts, color='steelblue', edgecolor='navy', alpha=0.8)\n",
        "\n",
        "ax.axhline(y=np.mean(class_counts), color='red', linestyle='--', \n",
        "           label=f'Moyenne: {np.mean(class_counts):.0f}')\n",
        "\n",
        "ax.set_xlabel('Classe de panneau', fontsize=12)\n",
        "ax.set_ylabel('Nombre d\\'images', fontsize=12)\n",
        "ax.set_title('Distribution des classes dans le dataset GTSRB', fontsize=14, fontweight='bold')\n",
        "ax.legend()\n",
        "ax.grid(axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(FIGURES_DIR, 'class_distribution.png'), dpi=150)\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nOn observe un desequilibre significatif entre les classes.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 Noms des 43 classes de panneaux"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Importer les noms de classes depuis notre module\n",
        "from data_preprocessing import CLASS_NAMES\n",
        "\n",
        "# Afficher les classes\n",
        "print(\"Les 43 classes de panneaux routiers:\\n\")\n",
        "for i, name in enumerate(CLASS_NAMES):\n",
        "    print(f\"   {i:2d}. {name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3 Visualisation d'exemples d'images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import csv\n",
        "\n",
        "# Charger un exemple de chaque classe\n",
        "fig, axes = plt.subplots(7, 7, figsize=(14, 14))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for class_id in range(43):\n",
        "    class_folder = os.path.join(DATA_PATH, format(class_id, '05d'))\n",
        "    \n",
        "    # Lire le premier fichier image\n",
        "    csv_file = os.path.join(class_folder, f'GT-{format(class_id, \"05d\")}.csv')\n",
        "    \n",
        "    with open(csv_file, 'r') as f:\n",
        "        reader = csv.reader(f, delimiter=';')\n",
        "        next(reader)  # Skip header\n",
        "        first_row = next(reader)\n",
        "        img_name = first_row[0]\n",
        "    \n",
        "    img_path = os.path.join(class_folder, img_name)\n",
        "    img = Image.open(img_path)\n",
        "    \n",
        "    ax = axes[class_id]\n",
        "    ax.imshow(img)\n",
        "    ax.set_title(f'{class_id}', fontsize=9)\n",
        "    ax.axis('off')\n",
        "\n",
        "# Cacher les axes restants\n",
        "for i in range(43, 49):\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.suptitle('Un exemple de chaque classe de panneau', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(FIGURES_DIR, 'sample_images.png'), dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 4. Prétraitement des données <a id='4-preprocessing'></a>\n",
        "\n",
        "### 4.1 Pipeline de prétraitement\n",
        "\n",
        "1. **Chargement** des images brutes\n",
        "2. **Redimensionnement** à 32×32 pixels (uniformisation)\n",
        "3. **Normalisation** des valeurs [0, 255] → [0, 1]\n",
        "4. **Encodage one-hot** des labels\n",
        "5. **Séparation** train/validation/test (70/15/15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Utiliser notre module de prétraitement\n",
        "from data_preprocessing import prepare_data, IMG_SIZE, NUM_CLASSES\n",
        "\n",
        "print(\"Configuration:\")\n",
        "print(f\"   Taille des images: {IMG_SIZE}×{IMG_SIZE} pixels\")\n",
        "print(f\"   Nombre de classes: {NUM_CLASSES}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Charger et prétraiter les données\n",
        "X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(DATA_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vérifier les dimensions\n",
        "print(\"\\nDimensions des donnees:\")\n",
        "print(f\"   X_train: {X_train.shape} | y_train: {y_train.shape}\")\n",
        "print(f\"   X_val:   {X_val.shape}  | y_val:   {y_val.shape}\")\n",
        "print(f\"   X_test:  {X_test.shape}  | y_test:  {y_test.shape}\")\n",
        "print(f\"\\n   Valeurs pixels: [{X_train.min():.3f}, {X_train.max():.3f}]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualiser quelques images prétraitées\n",
        "fig, axes = plt.subplots(2, 8, figsize=(16, 4))\n",
        "\n",
        "for i, ax in enumerate(axes.flatten()):\n",
        "    ax.imshow(X_train[i])\n",
        "    label = np.argmax(y_train[i])\n",
        "    ax.set_title(f'Classe {label}', fontsize=9)\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.suptitle('Exemples d\\'images après prétraitement (32×32, normalisées)', fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 5. Architecture du CNN <a id='5-architecture'></a>\n",
        "\n",
        "### 5.1 Conception de l'architecture\n",
        "\n",
        "Notre CNN est inspiré de l'architecture **VGGNet** avec des adaptations pour le GTSRB:\n",
        "\n",
        "| Composant | Description | Justification |\n",
        "|-----------|-------------|---------------|\n",
        "| **3 blocs conv** | 32→64→128 filtres | Extraction hiérarchique des features |\n",
        "| **BatchNorm** | Après chaque conv | Stabilise l'entraînement |\n",
        "| **MaxPooling 2×2** | Réduction spatiale | Invariance aux translations |\n",
        "| **Dropout 0.25** | Après pooling | Régularisation légère |\n",
        "| **Dense 512** | Avant softmax | Capacité de classification |\n",
        "| **Dropout 0.5** | Avant sortie | Régularisation forte |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Construire le modèle\n",
        "from model import build_cnn, print_model_architecture\n",
        "\n",
        "model = build_cnn(input_shape=(IMG_SIZE, IMG_SIZE, 3), num_classes=NUM_CLASSES)\n",
        "print_model_architecture(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualiser l'architecture\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "try:\n",
        "    plot_model(model, to_file=os.path.join(FIGURES_DIR, 'model_architecture.png'),\n",
        "               show_shapes=True, show_layer_names=True, dpi=150)\n",
        "    print(\"Architecture sauvegardee dans figures/model_architecture.png\")\n",
        "except Exception as e:\n",
        "    print(f\"Impossible de generer le graphique (graphviz non installe): {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 6. Entraînement du modèle <a id='6-training'></a>\n",
        "\n",
        "### 6.1 Hyperparamètres"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 30  # Ajuster selon le temps disponible\n",
        "LEARNING_RATE = 0.001\n",
        "\n",
        "print(\"Hyperparametres:\")\n",
        "print(f\"   Batch size: {BATCH_SIZE}\")\n",
        "print(f\"   Epochs: {EPOCHS}\")\n",
        "print(f\"   Learning rate: {LEARNING_RATE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compiler le modèle\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=LEARNING_RATE),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "print(\"Modele compile\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.2 Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "callbacks = [\n",
        "    # Sauvegarder le meilleur modèle\n",
        "    ModelCheckpoint(\n",
        "        filepath=os.path.join(MODELS_DIR, 'best_model.keras'),\n",
        "        monitor='val_accuracy',\n",
        "        mode='max',\n",
        "        save_best_only=True,\n",
        "        verbose=1\n",
        "    ),\n",
        "    \n",
        "    # Arrêt anticipé\n",
        "    EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=10,\n",
        "        restore_best_weights=True,\n",
        "        verbose=1\n",
        "    ),\n",
        "    \n",
        "    # Réduction du learning rate\n",
        "    ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,\n",
        "        patience=5,\n",
        "        min_lr=1e-6,\n",
        "        verbose=1\n",
        "    )\n",
        "]\n",
        "\n",
        "print(f\"{len(callbacks)} callbacks configures\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.3 Augmentation de données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Générateur avec augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,        # Rotation ±15°\n",
        "    width_shift_range=0.1,    # Translation horizontale ±10%\n",
        "    height_shift_range=0.1,   # Translation verticale ±10%\n",
        "    zoom_range=0.15,          # Zoom ±15%\n",
        "    shear_range=0.1,          # Cisaillement ±10°\n",
        "    fill_mode='nearest'\n",
        "    # PAS de flip horizontal/vertical (les panneaux ont un sens!)\n",
        ")\n",
        "\n",
        "datagen.fit(X_train)\n",
        "print(\"Data augmentation configuree\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.4 Lancement de l'entraînement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "print(\"Debut de l'entrainement...\\n\")\n",
        "\n",
        "history = model.fit(\n",
        "    datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),\n",
        "    steps_per_epoch=len(X_train) // BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=(X_val, y_val),\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"\\nEntrainement termine.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.5 Courbes d'apprentissage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tracer les courbes\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Loss\n",
        "ax1 = axes[0]\n",
        "ax1.plot(history.history['loss'], 'b-', label='Entraînement', linewidth=2)\n",
        "ax1.plot(history.history['val_loss'], 'r-', label='Validation', linewidth=2)\n",
        "ax1.set_xlabel('Époque')\n",
        "ax1.set_ylabel('Loss')\n",
        "ax1.set_title('Évolution de la Loss', fontweight='bold')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Accuracy\n",
        "ax2 = axes[1]\n",
        "ax2.plot(history.history['accuracy'], 'b-', label='Entraînement', linewidth=2)\n",
        "ax2.plot(history.history['val_accuracy'], 'r-', label='Validation', linewidth=2)\n",
        "ax2.set_xlabel('Époque')\n",
        "ax2.set_ylabel('Accuracy')\n",
        "ax2.set_title('Évolution de l\\'Accuracy', fontweight='bold')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "ax2.set_ylim([0, 1.05])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(FIGURES_DIR, 'training_curves.png'), dpi=150)\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nMeilleures performances:\")\n",
        "print(f\"   Val accuracy max: {max(history.history['val_accuracy']):.4f}\")\n",
        "print(f\"   Val loss min: {min(history.history['val_loss']):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 7. Évaluation des performances <a id='7-evaluation'></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Évaluation sur le jeu de test\n",
        "print(\"Evaluation sur le jeu de test...\\n\")\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "print(\"RESULTATS FINAUX:\")\n",
        "print(f\"   Test Loss:     {test_loss:.4f}\")\n",
        "print(f\"   Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prédictions sur le test set\n",
        "y_pred_proba = model.predict(X_test, verbose=0)\n",
        "y_pred = np.argmax(y_pred_proba, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "print(f\"Predictions effectuees: {len(y_pred)} echantillons\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7.1 Matrice de confusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculer et afficher la matrice de confusion\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "plt.figure(figsize=(16, 14))\n",
        "sns.heatmap(cm_normalized, annot=False, fmt='.2f', cmap='Blues',\n",
        "            xticklabels=range(43), yticklabels=range(43))\n",
        "plt.title('Matrice de Confusion (Normalisée)', fontsize=16, fontweight='bold')\n",
        "plt.xlabel('Prédiction', fontsize=12)\n",
        "plt.ylabel('Vérité terrain', fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(FIGURES_DIR, 'confusion_matrix.png'), dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7.2 Rapport de classification par classe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Rapport détaillé\n",
        "report = classification_report(y_true, y_pred, \n",
        "                               target_names=[f\"{i}\" for i in range(43)],\n",
        "                               digits=3)\n",
        "print(\"Rapport de classification:\\n\")\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 8. Analyse des erreurs <a id='8-errors'></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Trouver les indices des erreurs\n",
        "error_indices = np.where(y_pred != y_true)[0]\n",
        "correct_indices = np.where(y_pred == y_true)[0]\n",
        "\n",
        "print(\"Statistiques:\")\n",
        "print(f\"   Predictions correctes: {len(correct_indices)} ({len(correct_indices)/len(y_true)*100:.1f}%)\")\n",
        "print(f\"   Erreurs: {len(error_indices)} ({len(error_indices)/len(y_true)*100:.1f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8.1 Exemples de prédictions correctes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Afficher des prédictions correctes\n",
        "n_samples = 16\n",
        "selected = np.random.choice(correct_indices, min(n_samples, len(correct_indices)), replace=False)\n",
        "\n",
        "fig, axes = plt.subplots(4, 4, figsize=(12, 12))\n",
        "\n",
        "for i, idx in enumerate(selected):\n",
        "    ax = axes[i // 4, i % 4]\n",
        "    ax.imshow(X_test[idx])\n",
        "    conf = y_pred_proba[idx, y_pred[idx]] * 100\n",
        "    ax.set_title(f'Classe {y_true[idx]}\\nConf: {conf:.1f}%', fontsize=9, color='green')\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.suptitle('Exemples de Prédictions Correctes', fontsize=14, fontweight='bold', color='green')\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(FIGURES_DIR, 'correct_predictions.png'), dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8.2 Exemples d'erreurs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Afficher des erreurs\n",
        "n_samples = min(16, len(error_indices))\n",
        "selected = np.random.choice(error_indices, n_samples, replace=False)\n",
        "\n",
        "fig, axes = plt.subplots(4, 4, figsize=(12, 12))\n",
        "\n",
        "for i, idx in enumerate(selected):\n",
        "    ax = axes[i // 4, i % 4]\n",
        "    ax.imshow(X_test[idx])\n",
        "    conf = y_pred_proba[idx, y_pred[idx]] * 100\n",
        "    ax.set_title(f'Vrai: {y_true[idx]}\\nPrédit: {y_pred[idx]} ({conf:.1f}%)', \n",
        "                 fontsize=9, color='red')\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.suptitle('Exemples d\\'Erreurs de Prédiction', fontsize=14, fontweight='bold', color='red')\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(FIGURES_DIR, 'error_predictions.png'), dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8.3 Analyse des confusions les plus fréquentes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Trouver les erreurs les plus fréquentes\n",
        "cm_errors = cm.copy()\n",
        "np.fill_diagonal(cm_errors, 0)  # Ignorer les bonnes prédictions\n",
        "\n",
        "# Top 10 confusions\n",
        "errors_list = []\n",
        "for i in range(43):\n",
        "    for j in range(43):\n",
        "        if cm_errors[i, j] > 0:\n",
        "            errors_list.append((cm_errors[i, j], i, j))\n",
        "\n",
        "errors_list.sort(reverse=True)\n",
        "\n",
        "print(\"TOP 10 CONFUSIONS LES PLUS FREQUENTES\\n\")\n",
        "print(f\"{'Erreurs':<10} {'Vrai':<8} {'Predit':<8} {'Description'}\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "for count, true_class, pred_class in errors_list[:10]:\n",
        "    true_name = CLASS_NAMES[true_class][:15]\n",
        "    pred_name = CLASS_NAMES[pred_class][:15]\n",
        "    print(f\"{count:<10} {true_class:<8} {pred_class:<8} {true_name} -> {pred_name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 9. Conclusion et perspectives <a id='9-conclusion'></a>\n",
        "\n",
        "### 9.1 Résumé des performances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"RESUME DU PROJET\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(\"\\nPerformance finale:\")\n",
        "print(f\"   Accuracy sur test: {test_accuracy*100:.2f}%\")\n",
        "print(f\"   Loss sur test: {test_loss:.4f}\")\n",
        "\n",
        "print(\"\\nArchitecture:\")\n",
        "print(\"   3 blocs convolutifs (32->64->128 filtres)\")\n",
        "print(\"   BatchNormalization + Dropout\")\n",
        "print(\"   Dense 512 + Softmax 43 classes\")\n",
        "print(f\"   Total parametres: ~{model.count_params():,}\")\n",
        "\n",
        "print(\"\\nTechniques utilisees:\")\n",
        "print(\"   Data augmentation (rotation, translation, zoom)\")\n",
        "print(\"   Early stopping (patience=10)\")\n",
        "print(\"   Learning rate scheduling\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 9.2 Analyse critique\n",
        "\n",
        "**Points forts:**\n",
        "- Accuracy > 90% démontrant l'efficacité du CNN\n",
        "- Bonne généralisation (faible écart train/validation)\n",
        "- Robustesse aux variations grâce à l'augmentation\n",
        "\n",
        "**Limites:**\n",
        "- Confusion entre classes visuellement similaires (panneau de vitesse)\n",
        "- Déséquilibre des classes non traité explicitement\n",
        "- Taille des images réduites (perte potentielle d'information)\n",
        "\n",
        "### 9.3 Améliorations possibles\n",
        "\n",
        "1. **Transfer learning** avec un modèle pré-entraîné (ResNet, EfficientNet)\n",
        "2. **Class weighting** pour gérer le déséquilibre\n",
        "3. **Images plus grandes** (48×48 ou 64×64)\n",
        "4. **Ensemble de modèles** pour améliorer la robustesse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sauvegarder le modèle final\n",
        "model.save(os.path.join(MODELS_DIR, 'final_model.keras'))\n",
        "print(f\"Modele sauvegarde: {os.path.join(MODELS_DIR, 'final_model.keras')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "**Fin du notebook**\n",
        "\n",
        "Ce notebook a présenté l'implémentation complète d'un CNN pour la reconnaissance de panneaux routiers GTSRB, depuis le chargement des données jusqu'à l'analyse des erreurs. Les résultats obtenus démontrent l'efficacité des réseaux convolutifs pour ce type de tâche de classification d'images."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
